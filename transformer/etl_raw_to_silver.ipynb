{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce8ff08",
   "metadata": {},
   "source": [
    "# ETL Pipeline raw-to-silver - Uber Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-1",
   "metadata": {},
   "source": [
    "Este bloco importa todas as bibliotecas Python necessárias para o pipeline, como pandas para manipulação de dados, SQLAlchemy para interação com o banco de dados e logging para registrar o progresso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec16ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T00:10:28.563896Z",
     "iopub.status.busy": "2025-10-10T00:10:28.563653Z",
     "iopub.status.idle": "2025-10-10T00:10:28.986914Z",
     "shell.execute_reply": "2025-10-10T00:10:28.985861Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import TIMESTAMP, CHAR, Enum, FLOAT, INTEGER, VARCHAR\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c63d10",
   "metadata": {},
   "source": [
    "# Etapa 0 - Criando Função de Conexão com o Banco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-2",
   "metadata": {},
   "source": [
    "Define a função `connect_to_postgres` que estabelece a conexão com o banco de dados PostgreSQL. Ela usa variáveis de ambiente para as credenciais e se conecta ao `db_host` (definido como 'localhost' neste script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b70089f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T00:10:28.989887Z",
     "iopub.status.busy": "2025-10-10T00:10:28.989518Z",
     "iopub.status.idle": "2025-10-10T00:10:28.995766Z",
     "shell.execute_reply": "2025-10-10T00:10:28.994802Z"
    }
   },
   "outputs": [],
   "source": [
    "def connect_to_postgres():\n",
    "    db_user = os.getenv('POSTGRES_USER', 'admin')\n",
    "    db_password = os.getenv('POSTGRES_PASSWORD', 'admin')\n",
    "    db_name = os.getenv('POSTGRES_DB', 'postgres')\n",
    "    db_host = 'localhost' \n",
    "    \n",
    "    conn_string = f\"postgresql://{db_user}:{db_password}@{db_host}/{db_name}\"\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Tentando conectar ao Postgres...\")\n",
    "        engine = create_engine(conn_string)\n",
    "        connection = engine.connect()\n",
    "        logging.info(\"Conexão com o Postgres estabelecida com sucesso!\")\n",
    "        return engine, connection\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Falha ao conectar: {e}\")\n",
    "    \n",
    "    logging.critical(\"Não foi possível conectar ao banco de dados.\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a75f89",
   "metadata": {},
   "source": [
    "# Etapa 1 - Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-3",
   "metadata": {},
   "source": [
    "O script primeiro tenta estabelecer a conexão com o banco de dados chamando `connect_to_postgres`. Se bem-sucedido, ele lê o arquivo CSV ('uber-dataset.csv') do caminho especificado para um DataFrame pandas e registra o número de linhas lidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4687f376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T00:10:28.998505Z",
     "iopub.status.busy": "2025-10-10T00:10:28.998232Z",
     "iopub.status.idle": "2025-10-10T00:10:29.683291Z",
     "shell.execute_reply": "2025-10-10T00:10:29.682433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 10:31:13,623 - INFO - Tentando conectar ao Postgres...\n",
      "2025-11-08 10:31:13,652 - INFO - Conexão com o Postgres estabelecida com sucesso!\n",
      "2025-11-08 10:31:13,653 - INFO - Iniciando Etapa 1: Extract\n",
      "2025-11-08 10:31:14,155 - INFO - 150000 linhas lidas do arquivo CSV.\n"
     ]
    }
   ],
   "source": [
    "engine, connection = connect_to_postgres()\n",
    "\n",
    "if not engine:\n",
    "    raise RuntimeError(\"Não foi possível conectar ao banco de dados. Abortando o ETL.\")\n",
    "\n",
    "logging.info(\"Iniciando Etapa 1: Extract\")\n",
    "raw_path = '../data_layer/raw/uber-dataset.csv'\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "logging.info(f\"{len(df_raw)} linhas lidas do arquivo CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dba00c",
   "metadata": {},
   "source": [
    "# Etapa 2 - Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-4",
   "metadata": {},
   "source": [
    "Inicia a Etapa 2 (Transform). Este bloco executa as seguintes transformações específicas nos dados brutos:\n",
    "* Os nomes das colunas são padronizados para minúsculas e com underscores (ex: \"Booking ID\" -> \"booking_id\").\n",
    "* As colunas `date` e `time` são combinadas em uma única coluna `date_time` do tipo datetime.\n",
    "* Caracteres de aspas (`\"`) são removidos das colunas `booking_id` e `customer_id`.\n",
    "* Colunas de métricas (`avg_vtat`, `avg_ctat`, `booking_value`, `ride_distance`, `driver_ratings`, `customer_rating`) são convertidas para tipo numérico.\n",
    "* As colunas `cancelled_rides_by_customer` e `cancelled_rides_by_driver` são consolidadas na nova coluna `cancelled_by`.\n",
    "* As colunas `reason_for_cancelling_by_customer` e `driver_cancellation_reason` são consolidadas na nova coluna `reason_for_cancelling`.\n",
    "* O DataFrame final (`df_final`) é criado selecionando apenas as colunas necessárias e renomeando `driver_ratings` para `driver_rating`.\n",
    "\n",
    "**LÓGICA DE DUPLICATAS (CSV)**: Como último passo desta etapa, o script executa `df_final.drop_duplicates(subset=['booking_id'], keep='first')`. Isso remove quaisquer linhas *do próprio arquivo CSV* que tenham o mesmo `booking_id`, garantindo que apenas registros únicos avancem para a Etapa 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63516690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T00:10:29.685805Z",
     "iopub.status.busy": "2025-10-10T00:10:29.685566Z",
     "iopub.status.idle": "2025-10-10T00:10:29.991063Z",
     "shell.execute_reply": "2025-10-10T00:10:29.990062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 10:31:14,182 - INFO - Iniciando Etapa 2: Transform\n",
      "2025-11-08 10:31:14,268 - INFO - Limpando aspas dos IDs...\n",
      "2025-11-08 10:31:14,438 - INFO - Removidas 1233 duplicatas encontradas no arquivo CSV (baseado no 'booking_id').\n",
      "2025-11-08 10:31:14,438 - INFO - Transformação concluída. Schema final do DataFrame:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 148767 entries, 0 to 149999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   date_time               148767 non-null  datetime64[ns]\n",
      " 1   booking_id              148767 non-null  object        \n",
      " 2   booking_status          148767 non-null  object        \n",
      " 3   customer_id             148767 non-null  object        \n",
      " 4   vehicle_type            148767 non-null  object        \n",
      " 5   pickup_location         148767 non-null  object        \n",
      " 6   drop_location           148767 non-null  object        \n",
      " 7   avg_vtat                138366 non-null  float64       \n",
      " 8   avg_ctat                101175 non-null  float64       \n",
      " 9   cancelled_by            37191 non-null   object        \n",
      " 10  reason_for_cancelling   37191 non-null   object        \n",
      " 11  incomplete_ride_reason  8927 non-null    object        \n",
      " 12  booking_value           101175 non-null  Int64         \n",
      " 13  ride_distance           101175 non-null  float64       \n",
      " 14  driver_rating           92248 non-null   float64       \n",
      " 15  customer_rating         92248 non-null   float64       \n",
      " 16  payment_method          101175 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(5), object(10)\n",
      "memory usage: 20.6+ MB\n",
      "None\n",
      "            date_time  booking_id   booking_status customer_id   vehicle_type  \\\n",
      "0 2024-03-23 12:29:38  CNR5884300  No Driver Found  CID1982111          eBike   \n",
      "1 2024-11-29 18:01:39  CNR1326809       Incomplete  CID4604802       Go Sedan   \n",
      "2 2024-08-23 08:56:10  CNR8494506        Completed  CID9202816           Auto   \n",
      "3 2024-10-21 17:17:25  CNR8906825        Completed  CID2610914  Premier Sedan   \n",
      "4 2024-09-16 22:08:00  CNR1950162        Completed  CID9933542           Bike   \n",
      "\n",
      "       pickup_location      drop_location  avg_vtat  avg_ctat cancelled_by  \\\n",
      "0          Palam Vihar            Jhilmil       NaN       NaN         None   \n",
      "1        Shastri Nagar  Gurgaon Sector 56       4.9      14.0         None   \n",
      "2              Khandsa      Malviya Nagar      13.4      25.8         None   \n",
      "3  Central Secretariat           Inderlok      13.1      28.5         None   \n",
      "4     Ghitorni Village        Khan Market       5.3      19.6         None   \n",
      "\n",
      "  reason_for_cancelling incomplete_ride_reason  booking_value  ride_distance  \\\n",
      "0                   NaN                    NaN           <NA>            NaN   \n",
      "1                   NaN      Vehicle Breakdown            237           5.73   \n",
      "2                   NaN                    NaN            627          13.58   \n",
      "3                   NaN                    NaN            416          34.02   \n",
      "4                   NaN                    NaN            737          48.21   \n",
      "\n",
      "   driver_rating  customer_rating payment_method  \n",
      "0            NaN              NaN            NaN  \n",
      "1            NaN              NaN            UPI  \n",
      "2            4.9              4.9     Debit Card  \n",
      "3            4.6              5.0            UPI  \n",
      "4            4.1              4.3            UPI  \n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Iniciando Etapa 2: Transform\")\n",
    "df = df_raw.copy()\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "df['date_time'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')\n",
    "\n",
    "logging.info(\"Limpando aspas dos IDs...\")\n",
    "df['booking_id'] = df['booking_id'].str.strip('\"')\n",
    "df['customer_id'] = df['customer_id'].str.strip('\"')\n",
    "\n",
    "numeric_cols = ['avg_vtat', 'avg_ctat', 'booking_value', 'ride_distance', 'driver_ratings', 'customer_rating']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "conditions = [\n",
    "    df['cancelled_rides_by_customer'].notna(),\n",
    "    df['cancelled_rides_by_driver'].notna()\n",
    "]\n",
    "choices = ['customer', 'driver']\n",
    "df['cancelled_by'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "df['reason_for_cancelling'] = df['reason_for_cancelling_by_customer'].fillna(df['driver_cancellation_reason'])\n",
    "\n",
    "final_columns = {\n",
    "    'date_time': 'date_time',\n",
    "    'booking_id': 'booking_id',\n",
    "    'booking_status': 'booking_status',\n",
    "    'customer_id': 'customer_id',\n",
    "    'vehicle_type': 'vehicle_type',\n",
    "    'pickup_location': 'pickup_location',\n",
    "    'drop_location': 'drop_location',\n",
    "    'avg_vtat': 'avg_vtat',\n",
    "    'avg_ctat': 'avg_ctat',\n",
    "    'cancelled_by': 'cancelled_by',\n",
    "    'reason_for_cancelling': 'reason_for_cancelling',\n",
    "    'incomplete_rides_reason': 'incomplete_ride_reason',\n",
    "    'booking_value': 'booking_value',\n",
    "    'ride_distance': 'ride_distance',\n",
    "    'driver_ratings': 'driver_rating', \n",
    "    'customer_rating': 'customer_rating',\n",
    "    'payment_method': 'payment_method'\n",
    "}\n",
    "\n",
    "# Seleciona apenas as colunas que vamos usar\n",
    "df_final = df[final_columns.keys()]\n",
    "\n",
    "# Renomeia as colunas para o padrão final\n",
    "df_final = df_final.rename(columns=final_columns)\n",
    "\n",
    "\n",
    "df_final['booking_value'] = df_final['booking_value'].astype('Int64')\n",
    "\n",
    "\n",
    "total_before = len(df_final)\n",
    "df_final = df_final.drop_duplicates(subset=['booking_id'], keep='first')\n",
    "total_after = len(df_final)\n",
    "if total_before > total_after:\n",
    "    logging.info(f\"Removidas {total_before - total_after} duplicatas encontradas no arquivo CSV (baseado no 'booking_id').\")\n",
    "else:\n",
    "    logging.info(\"Nenhuma duplicata encontrada no arquivo CSV.\")\n",
    "\n",
    "\n",
    "logging.info(\"Transformação concluída. Schema final do DataFrame:\")\n",
    "print(df_final.info())\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0aa12",
   "metadata": {},
   "source": [
    "# Etapa 3 - Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-5",
   "metadata": {},
   "source": [
    "Esta etapa carrega o DataFrame `df_final` no banco de dados.\n",
    "\n",
    "* Define os tipos de dados das colunas para o banco (incluindo enums e tipos numéricos/texto).\n",
    "* Carrega o DataFrame usando `to_sql` com `if_exists='append'` e mapeamento de tipos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10c991d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T00:10:29.993759Z",
     "iopub.status.busy": "2025-10-10T00:10:29.993519Z",
     "iopub.status.idle": "2025-10-10T00:10:41.198915Z",
     "shell.execute_reply": "2025-10-10T00:10:41.197920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 10:31:14,501 - INFO - Iniciando Etapa 3: Load\n",
      "2025-11-08 10:31:14,502 - INFO - Iniciando carregamento de 148767 linhas...\n",
      "2025-11-08 10:31:27,416 - INFO - 148767 linhas carregadas com sucesso na tabela 'uber_silver'!\n",
      "2025-11-08 10:31:27,416 - INFO - Conexão com o banco de dados fechada.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.dialects.postgresql import ENUM\n",
    "\n",
    "logging.info(\"Iniciando Etapa 3: Load\")\n",
    "\n",
    "# Definição dos tipos SQL\n",
    "sql_types = {\n",
    "    'date_time': TIMESTAMP,\n",
    "    'booking_id': CHAR(10),\n",
    "    'booking_status': ENUM(\n",
    "        'No Driver Found', 'Incomplete', 'Completed', 'Cancelled by Driver', 'Cancelled by Customer',\n",
    "        name='booking_status_enum', create_type=False\n",
    "    ),\n",
    "    'customer_id': CHAR(10),\n",
    "    'vehicle_type': ENUM(\n",
    "        'eBike', 'Go Sedan', 'Auto', 'Premier Sedan', 'Bike', 'Go Mini', 'Uber XL',\n",
    "        name='vehicle_type_enum', create_type=False\n",
    "    ),\n",
    "    'pickup_location': VARCHAR(255),\n",
    "    'drop_location': VARCHAR(255),\n",
    "    'avg_vtat': FLOAT,\n",
    "    'avg_ctat': FLOAT,\n",
    "    'cancelled_by': ENUM(\n",
    "        'customer', 'driver', 'none',\n",
    "        name='cancelled_by_enum', create_type=False\n",
    "    ),\n",
    "    'reason_for_cancelling': ENUM(\n",
    "        'Driver is not moving towards pickup location', 'Driver asked to cancel', 'AC is not working', \n",
    "        'Change of plans', 'Wrong Address', 'Personal & Car related issues', 'Customer related issue', \n",
    "        'More than permitted people in there', 'The customer was coughing/sick',\n",
    "        name='cancellation_reason_enum', create_type=False\n",
    "    ),\n",
    "    'incomplete_rides_reason': ENUM(\n",
    "        'Vehicle Breakdown', 'Other Issue', 'Customer Demand',\n",
    "        name='incomplete_reason_enum', create_type=False\n",
    "    ),\n",
    "    'booking_value': INTEGER,\n",
    "    'ride_distance': FLOAT,\n",
    "    'driver_rating': FLOAT,\n",
    "    'customer_rating': FLOAT,\n",
    "    'payment_method': ENUM(\n",
    "        'UPI', 'Debit Card', 'Cash', 'Uber Wallet', 'Credit Card',\n",
    "        name='payment_method_enum', create_type=False\n",
    "    )\n",
    "}\n",
    "\n",
    "try:\n",
    "    table_name = 'uber_silver'\n",
    "    logging.info(f\"Iniciando carregamento de {len(df_final)} linhas...\")\n",
    "    df_final.to_sql(table_name, engine, if_exists='append', index=False, dtype=sql_types)\n",
    "    logging.info(f\"{len(df_final)} linhas carregadas com sucesso na tabela '{table_name}'!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro ao carregar dados no banco: {e}\")\n",
    "finally:\n",
    "    if 'connection' in locals() and not connection.closed:\n",
    "        connection.close()\n",
    "        logging.info(\"Conexão com o banco de dados fechada.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
